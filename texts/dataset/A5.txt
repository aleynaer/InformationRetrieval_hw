Alan Mathison Turing OBE FRS (/?tj??r??/; 23 June 1912 – 7 June 1954) was an English mathematician, computer scientist, logician, cryptanalyst, philosopher, and theoretical biologist.[6][7] Turing was highly influential in the development of theoretical computer science, providing a formalisation of the concepts of algorithm and computation with the Turing machine, which can be considered a model of a general-purpose computer.[8][9][10] Turing is widely considered to be the father of theoretical computer science and artificial intelligence.[11]

After Sherborne, Turing studied as an undergraduate from 1931 to 1934 at King's College, Cambridge,[7] where he was awarded first-class honours in mathematics. In 1935, at the age of 22, he was elected a Fellow of King's College on the strength of a dissertation in which he proved the central limit theorem.[45] Unknown to the committee, the theorem had already been proven, in 1922, by Jarl Waldemar Lindeberg.[46] A blue plaque at the college was unveiled on the centenary of his birth on 23 June 2012 and is now installed at the college's Keynes Building on King's Parade.[47][48]

In 1936, Turing published his paper "On Computable Numbers, with an Application to the Entscheidungsproblem".[49] It was published in the Proceedings of the London Mathematical Society journal in two parts, the first on 30 November and the second on 23 December.[50] In this paper, Turing reformulated Kurt Gödel's 1931 results on the limits of proof and computation, replacing Gödel's universal arithmetic-based formal language with the formal and simple hypothetical devices that became known as Turing machines. The Entscheidungsproblem (decision problem) was originally posed by German mathematician David Hilbert in 1928. Turing proved that his "universal computing machine" would be capable of performing any conceivable mathematical computation if it were representable as an algorithm. He went on to prove that there was no solution to the decision problem by first showing that the halting problem for Turing machines is undecidable: it is not possible to decide algorithmically whether a Turing machine will ever halt. This paper has been called "easily the most influential math paper in history".[51]


King's College, Cambridge, where Turing was a student in 1931 and became a Fellow in 1935. The computer room is named after him.
Although Turing's proof was published shortly after Alonzo Church's equivalent proof using his lambda calculus,[52] Turing's approach is considerably more accessible and intuitive than Church's.[53] It also included a notion of a 'Universal Machine' (now known as a universal Turing machine), with the idea that such a machine could perform the tasks of any other computation machine (as indeed could Church's lambda calculus). According to the Church–Turing thesis, Turing machines and the lambda calculus are capable of computing anything that is computable. John von Neumann acknowledged that the central concept of the modern computer was due to Turing's paper.[54] To this day, Turing machines are a central object of study in theory of computation.

From September 1936 to July 1938, Turing spent most of his time studying under Church at Princeton University,[4] in the second year as a Jane Eliza Procter Visiting Fellow. In addition to his purely mathematical work, he studied cryptology and also built three of four stages of an electro-mechanical binary multiplier.[55] In June 1938, he obtained his PhD from the Department of Mathematics at Princeton;[56] his dissertation, Systems of Logic Based on Ordinals,[57][58] introduced the concept of ordinal logic and the notion of relative computing, in which Turing machines are augmented with so-called oracles, allowing the study of problems that cannot be solved by Turing machines. John von Neumann wanted to hire him as his postdoctoral assistant, but he went back to the United Kingdom.[59]